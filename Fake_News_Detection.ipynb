{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvzvAQKa8+PkGNjQ5WNWej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuheli31/Fake-News-Detector/blob/main/Fake_News_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import re\n",
        "import string\n",
        "import requests\n",
        "from requests.utils import quote\n",
        "from urllib.parse import quote"
      ],
      "metadata": {
        "id": "msZS4f0WoM_w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter the news to verify if its real or fake"
      ],
      "metadata": {
        "id": "5x8oOFs0FoEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_check = input(\"Enter the news to verify if it is real or fake: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzQ1u30WE65l",
        "outputId": "6daa8108-35a0-4268-efbb-fc096d2a5793"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the news to verify if it is real or fake: trump tarrifs on india\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "Fdja1usdF1B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**G-News API (*Real News*)**"
      ],
      "metadata": {
        "id": "fOLut42OpXyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import quote\n",
        "import requests\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Your existing code ---\n",
        "news_api_key = 'd2b27a1e3f818564545508b6c744d24a'\n",
        "endpoint = 'search'\n",
        "question = input('Enter your question: ')\n",
        "parameters = f'q={quote(question)}&lang=en&max=5'\n",
        "news_api_url = f'https://gnews.io/api/v4/{endpoint}?{parameters}&apikey={news_api_key}'\n",
        "\n",
        "response = requests.get(news_api_url)\n",
        "data = response.json()\n",
        "\n",
        "if 'articles' in data:\n",
        "    articles_text = []  # to store article content for TF-IDF\n",
        "    articles_info = []  # to store article details for CSV\n",
        "\n",
        "    query_keywords = set(question.lower().split())\n",
        "\n",
        "    for idx, article in enumerate(data['articles']):\n",
        "        content = article['content'] if article['content'] else article['description']\n",
        "        articles_text.append(content)\n",
        "\n",
        "        # Keyword relevance %\n",
        "        content_words = set(content.lower().split())\n",
        "        relevant_words = query_keywords.intersection(content_words)\n",
        "        keyword_relevance = (len(relevant_words) / len(query_keywords)) * 100 if query_keywords else 0\n",
        "\n",
        "        articles_info.append({\n",
        "            'Published Time': article['publishedAt'],\n",
        "            'Title': article['title'],\n",
        "            'Description': article['description'],\n",
        "            'Content': content,\n",
        "            'Image': article['image'],\n",
        "            'Source Name': article['source']['name'],\n",
        "            'Source URL': article['source']['url'],\n",
        "            'Source Country': article['source']['country'],\n",
        "            'URL': article['url'],\n",
        "            'Keyword Relevance (%)': round(keyword_relevance, 2)\n",
        "        })\n",
        "\n",
        "    # --- TF-IDF & Cosine Similarity with query ---\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([question] + articles_text)  # include query as first row\n",
        "\n",
        "    # Cosine similarity between query (0th) and each article\n",
        "    similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
        "\n",
        "    # Add similarity scores to articles info\n",
        "    for i, score in enumerate(similarity_scores):\n",
        "        articles_info[i]['Similarity with Query'] = round(score, 3)\n",
        "\n",
        "    # Find most relevant article\n",
        "    most_relevant_idx = similarity_scores.argmax()\n",
        "    print(f\"\\nMost Relevant Article (Similarity {similarity_scores[most_relevant_idx]:.3f}):\")\n",
        "    print(f\"Title: {articles_info[most_relevant_idx]['Title']}\")\n",
        "    print(f\"Description: {articles_info[most_relevant_idx]['Description']}\")\n",
        "    print(f\"URL: {articles_info[most_relevant_idx]['URL']}\\n\")\n",
        "\n",
        "    # --- Save to CSV ---\n",
        "    df = pd.DataFrame(articles_info)\n",
        "    df = df.sort_values(by='Similarity with Query', ascending=False)  # sort by relevance\n",
        "    df.to_csv('news_articles_with_similarity.csv', index=False)\n",
        "    print(\"CSV saved as 'news_articles_with_similarity.csv'\")\n",
        "\n",
        "else:\n",
        "    print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd6poGBt6bJi",
        "outputId": "5bf517f8-c39d-4655-f699-13456c74dc13"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question: india pakistan war\n",
            "\n",
            "Most Relevant Article (Similarity 0.270):\n",
            "Title: 'Old Practice of Pakistan To Sponsor Terror & Blame Neighbours': MEA Rejects 'Proxy War' Claim\n",
            "Description: Earlier, Pakistan's Defence Minister Khawaja Asif accused India of having a hand in the military tensions between the Afghan Taliban and Pakistan and cast doubt on the 48-hour ceasefire with the Afghan government.\n",
            "URL: https://www.republicworld.com/world-news/old-practice-of-pakistan-to-sponsor-terror-blame-neighbours-mea-rejects-proxy-war-claim\n",
            "\n",
            "CSV saved as 'news_articles_with_similarity.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Twitter API**"
      ],
      "metadata": {
        "id": "Y0X91AiGrgx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for X (Twitter) API interaction\n",
        "import tweepy\n",
        "\n",
        "# Hardcoded Bearer Token\n",
        "X_API_BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAKCJ4QEAAAAAcEQy2tIw03BHpMFUg3fg9sbpGu8%3Db2Q2D7tbJUI2A0fJjOOMz69iKILmCmXeBYwVNNoxOaty3y2Oj2\"\n",
        "\n",
        "#Searching in tweets\n",
        "question = news_check.strip()\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if not X_API_BEARER_TOKEN or not question:\n",
        "    print(\"ERROR: Both the Bearer Token and the search query are required.\")\n",
        "else:\n",
        "    try:\n",
        "        # Initialize Tweepy Client\n",
        "        client = tweepy.Client(X_API_BEARER_TOKEN)\n",
        "\n",
        "        # API Call with image support\n",
        "        response = client.search_recent_tweets(\n",
        "            query=f'{question} -is:retweet has:images lang:en',\n",
        "            max_results=10,\n",
        "            tweet_fields=['created_at', 'public_metrics', 'attachments'],\n",
        "            user_fields=['name', 'username', 'verified'],\n",
        "            media_fields=['url', 'preview_image_url', 'type'],\n",
        "            expansions=['author_id', 'attachments.media_keys']\n",
        "        )\n",
        "\n",
        "        if not response or not response.data:\n",
        "            print(\"\\nNo recent tweets found for that query.\")\n",
        "        else:\n",
        "            tweets = response.data\n",
        "            users = {user['id']: user for user in response.includes.get('users', [])} if response.includes else {}\n",
        "            media = {m['media_key']: m for m in response.includes.get('media', [])} if response.includes else {}\n",
        "\n",
        "            print(\"\\n--- Found Tweets ---\\n\")\n",
        "            for tweet in tweets:\n",
        "                author = users.get(tweet.author_id)\n",
        "                media_urls = []\n",
        "\n",
        "                # Extract media URLs\n",
        "                if hasattr(tweet, 'attachments') and 'media_keys' in tweet.attachments:\n",
        "                    for key in tweet.attachments['media_keys']:\n",
        "                        if key in media and media[key].type == 'photo':\n",
        "                            media_urls.append(media[key].url)\n",
        "\n",
        "                tweet_url = f\"https://x.com/{author.username}/status/{tweet.id}\" if author else None\n",
        "                author_url = f\"https://x.com/{author.username}\" if author else None\n",
        "\n",
        "                print(f\"Published Time: {tweet.created_at}\")\n",
        "                print(f\"Tweet Text: {tweet.text}\")\n",
        "                if author:\n",
        "                    print(f\"Author Name: {author.name} (@{author.username})\")\n",
        "                    print(f\"Author URL: {author_url}\")\n",
        "                print(f\"Tweet URL: {tweet_url}\")\n",
        "\n",
        "                if media_urls:\n",
        "                    print(\"Image URLs:\")\n",
        "                    for img in media_urls:\n",
        "                        print(f\"- {img}\")\n",
        "                else:\n",
        "                    print(\"No images found.\")\n",
        "\n",
        "                print(\"\\n\")\n",
        "\n",
        "    except tweepy.errors.Unauthorized:\n",
        "        print(\"\\n--- AUTHENTICATION ERROR ---\")\n",
        "        print(\"The Bearer Token you provided is invalid. Please check your credentials on the X Developer Portal.\")\n",
        "    except tweepy.errors.BadRequest:\n",
        "        print(\"\\n--- INVALID SEARCH QUERY ---\")\n",
        "        print(\"Your search query is invalid or too complex. Please check the format.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred.\")\n",
        "        print(f\"Error details: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCAB5yObj148",
        "outputId": "5c03b69d-4a8a-44d1-b710-ff663264c86e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "An unexpected error occurred.\n",
            "Error details: 429 Too Many Requests\n",
            "Too Many Requests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reddit API**"
      ],
      "metadata": {
        "id": "9YCLcNrFrk_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG4IcqMhsL9r",
        "outputId": "1638e800-ae5d-4b07-9959-cd737e49d3db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from praw) (1.9.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from prawcore<3,>=2.4->praw) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.10.5)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: update_checker, prawcore, praw\n",
            "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for Reddit API interaction\n",
        "import praw\n",
        "import datetime # To format the timestamp from Reddit\n",
        "\n",
        "# --- API Configuration ---\n",
        "REDDIT_CLIENT_ID = 'utnSmiRRrv9ZDIlJ9LveMg'\n",
        "REDDIT_CLIENT_SECRET = 'jzP9XRolmRsu3CNiDZmKF0IDDGcXpA'\n",
        "REDDIT_USER_AGENT = 'python:moonsearcher:v1.0 (by /u/Dependent_Car_5879)'\n",
        "\n",
        "# --- Search Parameters ---\n",
        "try:\n",
        "    question = news_check.strip()\n",
        "    limit_str = input('How many results would you like? (e.g., 10): ').strip()\n",
        "    num_results = int(limit_str) if limit_str.isdigit() else 10\n",
        "except EOFError:\n",
        "    print(\"\\nNo input provided for search query. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "if not REDDIT_CLIENT_ID or not REDDIT_CLIENT_SECRET or not question:\n",
        "    print(\"ERROR: Client ID, Client Secret, and a search query are required.\")\n",
        "else:\n",
        "    try:\n",
        "        reddit = praw.Reddit(\n",
        "            client_id=REDDIT_CLIENT_ID,\n",
        "            client_secret=REDDIT_CLIENT_SECRET,\n",
        "            user_agent=REDDIT_USER_AGENT,\n",
        "        )\n",
        "\n",
        "        search_results = reddit.subreddit(\"all\").search(\n",
        "            query=question,\n",
        "            sort='new',\n",
        "            limit=num_results\n",
        "        )\n",
        "\n",
        "        submissions = list(search_results)\n",
        "\n",
        "        if not submissions:\n",
        "            print(\"\\nNo recent posts found for that query.\")\n",
        "        else:\n",
        "            print(f\"\\n--- Found {len(submissions)} Posts ---\\n\")\n",
        "            for submission in submissions:\n",
        "                author_name = submission.author.name if submission.author else \"[deleted]\"\n",
        "                post_url = f\"https://www.reddit.com{submission.permalink}\"\n",
        "                author_url = f\"https://www.reddit.com/user/{author_name}\" if author_name != \"[deleted]\" else \"N/A\"\n",
        "\n",
        "                published_time = datetime.datetime.fromtimestamp(submission.created_utc)\n",
        "\n",
        "                # --- Print basic info ---\n",
        "                print(f\"Published Time: {published_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "                print(f\"Post Title: {submission.title}\")\n",
        "                print(f\"Subreddit: r/{submission.subreddit.display_name}\")\n",
        "                print(f\"Score: {submission.score} (Upvote Ratio: {submission.upvote_ratio * 100:.0f}%)\")\n",
        "                print(f\"Author: u/{author_name}\")\n",
        "                print(f\"Author URL: {author_url}\")\n",
        "                print(f\"Post URL: {post_url}\")\n",
        "\n",
        "                # --- Print full text if available ---\n",
        "                if submission.selftext:\n",
        "                    print(f\"Post Text: {submission.selftext.replace(chr(10), ' ')}\")\n",
        "\n",
        "                # --- Extract image if any ---\n",
        "                image_url = None\n",
        "                if submission.url.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
        "                    image_url = submission.url\n",
        "                elif hasattr(submission, 'preview'):\n",
        "                    try:\n",
        "                        image_url = submission.preview['images'][0]['source']['url']\n",
        "                    except (KeyError, IndexError):\n",
        "                        pass\n",
        "\n",
        "                if image_url:\n",
        "                    print(f\"Image URL: {image_url}\")\n",
        "                else:\n",
        "                    print(\"Image: None\")\n",
        "\n",
        "                print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
        "\n",
        "    except praw.exceptions.PRAWException as e:\n",
        "        print(\"\\n--- API ERROR ---\")\n",
        "        print(\"An error occurred with the Reddit API. This could be due to invalid credentials or a connection problem.\")\n",
        "        print(f\"Error details: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred.\")\n",
        "        print(f\"Error details: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEzHFodMoLVj",
        "outputId": "b2206054-6bc1-49ac-c2e2-b9e452103356"
      },
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many results would you like? (e.g., 10): 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Found 10 Posts ---\n",
            "\n",
            "Published Time: 2025-10-17 13:48:43\n",
            "Post Title: [Business] - 'They forced me to do it': Trump says high tariffs on China 'not sustainable'; claims Beijing 'ripped off' America for years | Times of India\n",
            "Subreddit: r/AutoNewspaper\n",
            "Score: 1 (Upvote Ratio: 100%)\n",
            "Author: u/AutoNewspaperAdmin\n",
            "Author URL: https://www.reddit.com/user/AutoNewspaperAdmin\n",
            "Post URL: https://www.reddit.com/r/AutoNewspaper/comments/1o91toa/business_they_forced_me_to_do_it_trump_says_high/\n",
            "Image URL: https://external-preview.redd.it/DVilcudRw1IlSPuY9W-m-XMu3HMC1bHH8gZYE-tl6uw.jpeg?auto=webp&s=8021460ddb665f156cdff3cc8fd1058cb7bdd0c5\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 13:40:21\n",
            "Post Title: The left doesn't care what Trump does or doesn't do.\n",
            "Subreddit: r/AskThe_Donald\n",
            "Score: 13 (Upvote Ratio: 73%)\n",
            "Author: u/Pikachu_USA\n",
            "Author URL: https://www.reddit.com/user/Pikachu_USA\n",
            "Post URL: https://www.reddit.com/r/AskThe_Donald/comments/1o91mfk/the_left_doesnt_care_what_trump_does_or_doesnt_do/\n",
            "Post Text: They just care that he's the one doing it.   Here are some actions he's taken that they would otherwise support if it were literally anyone else. And if he hadn't done anything they'd bitch and moan on his inaction anyway:   **Trump is a huge advocate for ceasefires and hostage releases** Trump has advocated for multiple peace deals: the Israel-Hamas ceasefire with hostage releases. As well as ceasefires between Armenia-Azerbaijan, India-Pakistan, Rwanda-Democratic Republic of Congo, and Thailand-Cambodia. There have been no new U.S. wars started, and over 50 American hostages have been freed worldwide. He's also meeting with Putin on Friday to try a ceasefire on Ukraine. Lefties should be overjoyed over this..   **Trump reduced prescription drug prices** The left should be thrilled that healthcare is a bit more affordable now. And I think both sides can agree this is a good thing. Screw big pharma.   **Trump's tariffs on China** This use to be supported by the left all throughout the 90s and well into the 2010s before Trump's first term. They would have applauded him for taking a great measure on humanitarian efforts that addresses low-wages and poor working conditions of global trade markets. They're just mad Trump did it for pro-USA, instead of anti-slave-level-labor. It's still the same result. But orange man bad.   **Trump leveled the NATO field and reduced US military overextension** So now NATO allies are putting a bit more on their behalf. So this cuts US military spending that can be invested into domestic priorities. Lefties used to criticize endless US interventions. Now they celebrate it? Either way a good thing all around.   **Trump has implemented stricter border policies with a humanitarian focus** Yes you read that right. Trump advocates for safe, legal, and structured immigration. It's not safe for illegals, or citizens, for them to part take in exploitative paths into the US. Aside from how sketchy it is for someone to break into our country illegally, wouldn't we want to know who these people are? Refugees are applicants seeking entry into the US. Asylees apply after they break in. Therefore wouldn't we want to encourage more refugees? That way they are safe before they enter the country? Trump deserves applause from the left. They just like to stay in their bubble of ignorance.   **Healthier food guidelines and grocery price reductions** Trump's new guidelines promote healthier, cheaper foods, eliminated certain food dyes, and deregulated agriculture, which has led to a 3.4% drop in grocery prices. Liberals have campaigned for years for food safety reforms, reduced chemical additives, and affordable nutrition and anti-corporate agendas. Oh and you can't get junk food on snap now.   .  .  .  Trump is truly a man of the people. He grew up in the metropolis of New York and it's evident. He's honestly not as right-leaning as the left makes him out to be. What do you think makes the liberals hate him so much that they keep wedging our country into further division??   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 12:19:06\n",
            "Post Title: 📰📰📰📰📰📰📰📰📰🆕🆕🆕🆕🆕🆕 Stock Market Morning Prep\n",
            "Subreddit: r/Optionmillionaires\n",
            "Score: 3 (Upvote Ratio: 100%)\n",
            "Author: u/upbstock\n",
            "Author URL: https://www.reddit.com/user/upbstock\n",
            "Post URL: https://www.reddit.com/r/Optionmillionaires/comments/1o8zr2h/stock_market_morning_prep/\n",
            "Post Text: New lawsuit: The U.S. Chamber of Commerce is suing the Trump administration over a $100,000 annual fee on H-1B visas, calling it unlawful and economically damaging to American businesses.  Investing and betting: CME plans to roll out financial contracts tied to both sports games and economic indicators, in a move similar to tie-ups like Intercontinental Exchange-Polymarket and Robinhood-Kalshi.  On the decline? \"I'm more sanguine than my colleagues about inflation,\" Federal Reserve Governor Stephen Miran declared, because he expects \"significant disinflation\" in housing.  Sour loans As Warren Buffett once famously said, \"There is seldom just one cockroach in the kitchen.\" That saying is now being echoed by the top brass of the financial world, with big banks to regional players taking substantial loan loss charges this week amid fears over the health of their lending businesses. Whether these are credit \"one-offs\" is soon to be seen, but the market is getting nervous until the landscape becomes clearer.  Backdrop: Red flags first appeared last month after auto parts maker First Brands went bankrupt, which was quickly followed by a Chapter 7 filing at subprime auto lender Tricolor Holdings. Unsustainable levels of debt, as well as fraudulent and murky activity, were said to be at the heart of the crisis, including \"double-pledging\" and \"off-balance-sheet financing.\" The developments quickly sent shockwaves through the financial industry, which would soon report its latest results for the quarter.  Major banks, like JPMorgan Chase (JPM), took a $170M charge-off related to its Tricolor exposure, which CEO Jamie Dimon publicly called \"not our finest moment\" and also used a waterbug reference. \"When you see one cockroach, there are probably more,\" he declared, before many more banks revealed additional fallout. Jefferies (NYSE:JEF), Western Alliance (WAL) and Zions Bancorp (NASDAQ:ZION) all tumbled more than 10% on Thursday after tallying hundreds of millions of dollars in potential losses, while other regional bank players also sold off in a flashback to the Silicon Valley Bank crisis of 2023.  It's spreading... Treasury yields fell sharply, and the Fed's standing repo facility was tapped for the second day running, indicating illiquidity across money markets. Equities across Europe and Asia also sold off, while U.S. stock index futures point to another down day on Wall Street. While there is a lot of fear at the moment, it's important to note that cockroaches are likely not representative of a systemic banking crisis, though it is still good to keep an eye on the shadows. (10 comments)  Here's the latest Seeking Alpha analysis  If I Could Own Just 5 Stocks, These Would Be It  Afraid Of The AI Bubble? Just Buy Amazon Stock  B2Gold: The Ultimate Gold Play  AMD: Business Hypergrowth In Sight, I'm A Buyer  Oracle: The Beginning Of A Long Rally  What else is happening...  China's rare earth export controls spark global pushback.  U.S.-Canada trade talks: Keystone XL's restart on the table.  These U.S. banks are in talks to give Argentina a $20B loan.  Trump to meet Putin again, but Zelenskyy sit-down set for today.  Oracle (ORCL) sees AI data center margins at 30%-40%.  Apple (AAPL) targets touchscreen MacBook launch in 2026.  Lithium Americas (LAC) sinks as JPM cuts to Sell after big rally.  Boeing St. Louis strike: Union files unfair labor practice charge.  Spirit (OTC:FLYYQ) to furlough another 365 pilots next year.  Gen Z protest wave: Peru set to declare state of emergency.  Today's Markets  In Asia, Japan -1.4%. Hong Kong -2.5%. China -2%. India +0.6%. In Europe, at midday, London -1.3%. Paris -0.8%. Frankfurt -2.1%. Futures at 6:30, Dow -0.8%. S&P -1.1%. Nasdaq -1.4%. Crude -1.2% to $56.31. Gold +1.1% to $4,350.20. Bitcoin -6.6% to $104,038. Ten-year Treasury Yield -1 bp to 3.96%.  On The Calendar  Companies reporting today include SLB (SLB) and American Express (AXP).\n",
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 10:48:53\n",
            "Post Title: Where America is and is headed\n",
            "Subreddit: r/Discussion\n",
            "Score: 3 (Upvote Ratio: 100%)\n",
            "Author: u/Golfandrun\n",
            "Author URL: https://www.reddit.com/user/Golfandrun\n",
            "Post URL: https://www.reddit.com/r/Discussion/comments/1o8y0st/where_america_is_and_is_headed/\n",
            "Post Text: These are not my words. I got this piece from another source, but they're good words.  \"October 16, 2025 (Thursday) Heather Cox Richardson   Yesterday the Trump administration announced it would pay furloughed troops by using funds Congress appropriated for research, development, testing, and evaluation (RDTE) for fiscal year 2026. Today White House press secretary Karoline Leavitt said Trump had “found a creative solution to keep the troops paid. And rather than congratulate the president for doing that, this unprecedented action to get our troops paid, the Democrats want to sue him for it. They’re saying that it’s illegal.”  Democrats are saying it’s illegal because it is illegal. The Antideficiency Act, a law that has evolved over time since 1870, prohibits the government from spending money that Congress has not appropriated for that purpose, or agreeing to contracts that spend money Congress has not appropriated for that purpose.   This summer, Democratic senators charged Homeland Security Secretary Kristi Noem with triggering the Antideficiency Act by overspending her department’s budget, but Trump’s claim that he can move government money around as he wishes is an even greater threat to the country than Noem’s overspending.   There is more at stake here than a broken law.   Trump’s assumption of power over the government’s purse is a profound attack on the principles on which the Founders justified independence from King George III in 1776. The Founders stood firm on the principle articulated all the way back to the Magna Carta in 1215 that the government could not spend money without consulting those putting up that money by paying taxes.  That principle was at the heart of the American Revolution. The 1773 Tea Act that sparked Sons of Liberty in Boston, Massachusetts, to throw chests of tea into Boston Harbor did not raise the price of tea in the colonies; the law lowered those prices. To pay for the cost of what colonists knew as the French and Indian War, Parliament in 1767 had taxed glass, lead, oil, paint, paper, and tea, but boycotts and protests had forced Parliament to repeal all the taxes except the one on tea. It kept that tax to maintain the principle that it could tax the colonies despite the fact they were unrepresented in that body.  Then, in 1773, Parliament gave a monopoly on colonial tea sales to the foundering British East India Tea Company. That monopoly would have the effect of lowering the price of tea. Lower prices should persuade colonists to buy the tea despite the tax, thus cementing the principle that Parliament could tax the colonies without their consent. But colonists protested the maneuver. In December 1773, the Sons of Liberty held what became known as the Boston Tea Party, ruining newly arrived chests of tea by throwing them into the harbor, thus paving the route to the American Revolution.   When leaders from the former colonies wrote the U.S. Constitution in 1787, they made sure the people retained control over the nation’s finances in order to guarantee that a demagogue could not use tax money to concentrate power in his own hands. They gave the power to write the laws to the legislative branch—the House of Representatives and the Senate—alone, giving the president power only to agree to or veto those measures. Once the laws were enacted, the president’s role was to “take Care that the Laws be faithfully executed.”    To make sure that the power of the purse remained in the hands of the people, the Framers wrote into the Constitution that “[a]ll Bills for raising Revenue shall originate in the House of Representatives.”   Trump’s declaration that he will ignore the laws Congress passed and take it upon himself to spend money as he wishes undermines not just the Antideficiency Act but also the fundamental principle that the American people must have control over their own finances. That Leavitt suggests giving up that principle to pay the troops, which lawmakers agree is imperative but cannot write into law because Speaker Mike Johnson (R-LA) will not recall the House of Representatives, echoes the Tea Act that would have thrown away the principle of having a say in government for cheaper tea.  Since Trump took office, his administration has undermined the principle that Congress controls funding. It had withheld funds Congress appropriated, a practice that violates the 1974 Impoundment Act and the Constitution. The cost of such impoundment became evident on Sunday, when catastrophic flooding hit the village of Kipnuk, Alaska, a disaster Andrew Freedman of CNN notes was exacerbated by the lack of weather data after cuts left a critical shortage in weather balloon coverage in the area.   Earlier this year the administration cancelled a $20 million Biden-era Environmental Protection Agency (EPA) grant awarded to the community to prevent flooding. Maxine Joselow and Lisa Friedman of the New York Times noted that when EPA administrator Lee Zeldin cut grants this year, he boasted that he was eliminating “wasteful [diversity, equity, and inclusion] and Environmental Justice grants.”   Now that the government is shut down, Trump has told reporters that his administration is using the shutdown to take funds Congress appropriated away from Democratic districts. Tony Romm and Lazaro Gamio of the New York Times estimate that the administration has cancelled more than $27.24 billion in funds for Democratic districts and states while cutting $738.7 million from Republican districts and states. Speaker Johnson told reporters he thought such withholding was both lawful and constitutional but did not explain his reasoning.   Today Annie Grayer and Adam Cancryn of CNN reported that not just Democratic representatives but also Republicans are out of the loop of presidential funding cuts, finding out about cuts to their districts through press releases. Even Senator Susan Collins (R-ME), the chair of the Senate Appropriations Committee, said “we are really not consulted.”   Speaker Johnson told CNN that he hasn’t received details about the administration’s offer of $20 billion in public money and another $20 billion in private-sector financing to Argentina to prop up the government of Trump’s right-wing ally Javier Milei before upcoming elections there.   Trump is also taking control of the previously nonpartisan Department of Justice (DOJ). Yesterday, in the Oval Office, Trump stood in front of three top officials from the DOJ and called for investigations into former deputy attorney general in the Biden administration Lisa Monaco; former FBI official Andrew Weissman, who led the team investigating the ties  between Trump’s 2016 campaign and Russian operatives; former special counsel Jack Smith, who investigated and indicted Trump for the events of January 6 and for retaining classified documents; and Representative Adam Schiff (D-CA), who led the House impeachment team in Trump’s first impeachment trial.    Glenn Thrush of the New York Times noted the DOJ officials “smiled, nodded and shuffled in place as he spoke.”  Today a federal grand jury in Maryland indicted John Bolton, who served as national security advisor in Trump’s first term, alleging that he shared classified information in the form of a diary with two of his relatives. That material later informed his book The Room Where It Happened: A White House Memoir, which covered his time in the first Trump administration and so infuriated Trump that he tried to stop its publication.   The grand jury charged Bolton with eight counts of communicating secret information with those not entitled to receive it, and ten counts of having unauthorized possession of documents containing secret information. These charges are similar to those Jack Smith brought against Trump himself, although Trump’s election to a second term stopped that prosecution.  The indictment references Bolton’s criticism of the Trump administration's handling of secret information, in particular Defense Secretary Pete Hegseth’s use of the Signal messaging app to plan a military strike on the Houthis in Yemen, especially after a journalist had been added to the call, and Hegseth’s additional Signal chat about the strike with family and friends.   A court will determine the merits of the case against Bolton, but there is no doubt it is intended to send a signal to others in government that Trump will persecute those whom he perceives as disloyal.   Today, Steady State, a group made up of more than 340 former U.S. intelligence officers from the Central Intelligence Agency, the National Security Agency, the State Department, and other intelligence agencies, released a report assessing the state of American democracy. Applying the tools of their craft to the U.S., they assess that the nation is “on a trajectory toward competitive authoritarianism: a system in which elections, courts, and other democratic institutions persist in form but are systematically manipulated to entrench executive control.”    The report, titled Accelerating Authoritarian Dynamics: Assessment of Democratic Decline, finds that American democracy is weakening as the Executive Branch is consolidating power and “actively weaponizing state institutions to punish perceived opponents and shield allies,” and that Congress is refusing to check the president, “creating openings for authoritarian exploitation.”   “We judge that the primary driver of the U.S.’s increasing authoritarianism is the increased frequency of Executive Branch overreach,” the report says, noting that “President Donald J. Trump has leveraged emergency powers, executive orders, federalized military forces, and bureaucratic politicization to consolidate control and weaken checks and balances.”  But the Trump administration is increasingly unpopular. Trump loyalists are working overtime to portray those who oppose the administration as anti-American criminals and terrorists. Today White House press secretary Leavitt told the Fox News Channel that “[t]he Democrat Party's main constituency are [sic] made up of Hamas terrorists, illegal aliens, and violent criminals,” and administration loyalists have spent the week claiming that the No Kings rally scheduled for Saturday, October 18, is a “hate America rally.”   Joe Perticone of The Bulwark noted that Indivisible, the organization sponsoring the No Kings protests, “has an extensive track record that shows a longstanding emphasis on safety and nonviolence.” Perticone spoke to Ezra Levin, co–executive director of Indivisible, who said: “Go to a No Kings rally. What do you see? You see moms and grandmas and kids and dogs and funny signs and dancing and happy displays of opposition to the regime that are foundationally nonviolent. And on the other end, you’ve got a regime that’s led by a guy who cheered the January 6th insurrection.”   Levin noted that authoritarian regimes fear mass organizing and peaceful protest because they reveal a regime’s unpopularity and show that it is losing its grip on power.   Much as tossing chests of tea into Boston Harbor did about 250 years ago.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 10:29:51\n",
            "Post Title: India contradicts Trump on Russian oil pledge\n",
            "Subreddit: r/qualitynews\n",
            "Score: 29 (Upvote Ratio: 96%)\n",
            "Author: u/donutloop\n",
            "Author URL: https://www.reddit.com/user/donutloop\n",
            "Post URL: https://www.reddit.com/r/qualitynews/comments/1o8xpf1/india_contradicts_trump_on_russian_oil_pledge/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 10:29:07\n",
            "Post Title: India contradicts Trump on Russian oil pledge\n",
            "Subreddit: r/AnythingGoesNews\n",
            "Score: 3 (Upvote Ratio: 100%)\n",
            "Author: u/donutloop\n",
            "Author URL: https://www.reddit.com/user/donutloop\n",
            "Post URL: https://www.reddit.com/r/AnythingGoesNews/comments/1o8xoyo/india_contradicts_trump_on_russian_oil_pledge/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 10:28:55\n",
            "Post Title: India contradicts Trump on Russian oil pledge\n",
            "Subreddit: r/inthenews\n",
            "Score: 3 (Upvote Ratio: 80%)\n",
            "Author: u/donutloop\n",
            "Author URL: https://www.reddit.com/user/donutloop\n",
            "Post URL: https://www.reddit.com/r/inthenews/comments/1o8xouy/india_contradicts_trump_on_russian_oil_pledge/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 10:28:41\n",
            "Post Title: India contradicts Trump on Russian oil pledge\n",
            "Subreddit: r/news2\n",
            "Score: 1 (Upvote Ratio: 100%)\n",
            "Author: u/donutloop\n",
            "Author URL: https://www.reddit.com/user/donutloop\n",
            "Post URL: https://www.reddit.com/r/news2/comments/1o8xoqf/india_contradicts_trump_on_russian_oil_pledge/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 10:28:30\n",
            "Post Title: India contradicts Trump on Russian oil pledge\n",
            "Subreddit: r/NoFilterNews\n",
            "Score: 1 (Upvote Ratio: 100%)\n",
            "Author: u/donutloop\n",
            "Author URL: https://www.reddit.com/user/donutloop\n",
            "Post URL: https://www.reddit.com/r/NoFilterNews/comments/1o8xomf/india_contradicts_trump_on_russian_oil_pledge/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Published Time: 2025-10-17 09:52:28\n",
            "Post Title: India contradicts Trump on Russian oil pledge\n",
            "Subreddit: r/energy\n",
            "Score: 9 (Upvote Ratio: 100%)\n",
            "Author: u/donutloop\n",
            "Author URL: https://www.reddit.com/user/donutloop\n",
            "Post URL: https://www.reddit.com/r/energy/comments/1o8x3b9/india_contradicts_trump_on_russian_oil_pledge/\n",
            "Image: None\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "yzWJMI0h1Lst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n",
        "!pip install beautifulsoup4 spacy scikit-learn\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfOl9F9m-4ih",
        "outputId": "db9e2052-8025-4fc6-bc55-d51cffd015fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/608.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m522.2/608.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.15.0\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.19.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Real news data in csv file*"
      ],
      "metadata": {
        "id": "jfr6QW5G9BJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rake_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0gbgmB4nkhq",
        "outputId": "edce8885-8382-4bd5-a46d-4d6d2f3d83d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake_nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from rake_nltk) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.67.1)\n",
            "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: rake_nltk\n",
            "Successfully installed rake_nltk-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "from bs4 import BeautifulSoup\n",
        "import emoji\n",
        "import re\n",
        "import pandas as pd\n",
        "from rake_nltk import Rake\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# --- GNews API Config ---\n",
        "news_api_key = 'd2b27a1e3f818564545508b6c744d24a'\n",
        "endpoint = 'search'\n",
        "\n",
        "# --- Functions ---\n",
        "def clean_text(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.lower().strip()\n",
        "\n",
        "def extract_keywords_from_query(query, max_keywords=7):\n",
        "    \"\"\"Extract top keywords and ensure compatibility with past news searches.\"\"\"\n",
        "    r = Rake()\n",
        "    r.extract_keywords_from_text(query)\n",
        "    keywords = r.get_ranked_phrases()[:max_keywords]\n",
        "\n",
        "    # Remove real-time trigger words to allow historical search\n",
        "    forbidden_words = ['latest', 'breaking', 'new', 'recent', 'update', 'today', 'tonight']\n",
        "    filtered_keywords = [kw for kw in keywords if all(fw not in kw.lower() for fw in forbidden_words)]\n",
        "\n",
        "    # Add neutral word to force GNews historical search\n",
        "    if filtered_keywords:\n",
        "        filtered_keywords.append(\"report\")\n",
        "\n",
        "    return \" \".join(filtered_keywords)\n",
        "\n",
        "def fetch_news(query, max_results=5):\n",
        "    parameters = f'q={quote(query)}&lang=en&max={max_results}'\n",
        "    news_api_url = f'https://gnews.io/api/v4/{endpoint}?{parameters}&apikey={news_api_key}'\n",
        "    response = requests.get(news_api_url)\n",
        "    print(\"\\n--- Fetching News ---\")\n",
        "    print(\"Request URL:\", news_api_url)\n",
        "    print(\"Status Code:\", response.status_code)\n",
        "    print(\"Raw Response (first 500 chars):\", response.text[:500])\n",
        "    return response.json().get('articles', [])\n",
        "\n",
        "def preprocess_articles(articles):\n",
        "    processed = []\n",
        "    for article in articles:\n",
        "        full_text = (article.get('title','') + \" \" +\n",
        "                     article.get('description','') + \" \" +\n",
        "                     article.get('content',''))\n",
        "        processed.append({\n",
        "            \"published_at\": article.get('publishedAt', ''),\n",
        "            \"title\": clean_text(article.get('title', '')),\n",
        "            \"description\": clean_text(article.get('description', '')),\n",
        "            \"content\": clean_text(article.get('content', '')),\n",
        "            \"full_text\": clean_text(full_text),\n",
        "            \"image\": article.get('image', ''),\n",
        "            \"source_name\": article['source'].get('name', ''),\n",
        "            \"source_url\": article['source'].get('url', ''),\n",
        "            \"source_country\": article['source'].get('country', ''),\n",
        "            \"article_url\": article.get('url', '')\n",
        "        })\n",
        "    return pd.DataFrame(processed)\n",
        "\n",
        "def calculate_relevance(df, query):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([query] + df['full_text'].tolist())\n",
        "    similarities = cosine_similarity(vectors[0:1], vectors[1:]).flatten()\n",
        "    df[\"relevance_score\"] = similarities\n",
        "    df = df.sort_values(by=\"relevance_score\", ascending=False)\n",
        "    return df\n",
        "\n",
        "# --- Main ---\n",
        "question = news_check  # User can enter a long paragraph, a few keywords, or request past news\n",
        "\n",
        "# Step 1: Extract keywords and clean query\n",
        "keyword_query = extract_keywords_from_query(question)\n",
        "print(\"Keyword Query:\", keyword_query)\n",
        "\n",
        "# Step 2: Fetch articles\n",
        "articles = fetch_news(keyword_query)\n",
        "\n",
        "if not articles:\n",
        "    print(\"⚠️ No articles found or API limit reached.\")\n",
        "else:\n",
        "    df = preprocess_articles(articles)\n",
        "\n",
        "    # Step 3: Rank by relevance to original query\n",
        "    df = calculate_relevance(df, question)\n",
        "\n",
        "    print(df[['title', 'relevance_score', 'article_url']])\n",
        "    df.to_csv('preprocessed_news.csv', index=False)\n",
        "    print(\"\\nData saved to 'preprocessed_news.csv'.\")\n"
      ],
      "metadata": {
        "id": "VDlL0c3G1BIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c84e5c-b127-4fcf-c3a3-5717460e3b67"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyword Query: india pakistan war report\n",
            "\n",
            "--- Fetching News ---\n",
            "Request URL: https://gnews.io/api/v4/search?q=india%20pakistan%20war%20report&lang=en&max=5&apikey=d2b27a1e3f818564545508b6c744d24a\n",
            "Status Code: 200\n",
            "Raw Response (first 500 chars): {\"information\":{\"realTimeArticles\":{\"message\":\"Real-time news data is only available on paid plans. Free plan has a 12-hour delay. Upgrade your plan here to remove the delay: https://gnews.io/change-plan\"}},\"articlesRemovedFromResponse\":{\"historicalArticles\":{\"message\":\"4 articles were removed from the response because historical data beyond 30 days is only available on paid plans. Upgrade your plan here to access historical data: https://gnews.io/change-plan\"}},\"totalArticles\":18,\"articles\":[{\"\n",
            "                                               title  relevance_score  \\\n",
            "0  aakar patel | the new new india: kicked around...         0.102513   \n",
            "\n",
            "                                         article_url  \n",
            "0  https://www.deccanchronicle.com/opinion/column...  \n",
            "\n",
            "Data saved to 'preprocessed_news.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Twitter datas in csv file*"
      ],
      "metadata": {
        "id": "TPPFxqP69Y_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Import libraries ---\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "from bs4 import BeautifulSoup\n",
        "import tweepy\n",
        "import spacy\n",
        "\n",
        "# --- Load SpaCy model for keyword extraction ---\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- Your X API Bearer Token ---\n",
        "X_API_BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAKCJ4QEAAAAAcEQy2tIw03BHpMFUg3fg9sbpGu8%3Db2Q2D7tbJUI2A0fJjOOMz69iKILmCmXeBYwVNNoxOaty3y2Oj2\"\n",
        "\n",
        "# --- Functions ---\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text: remove HTML, emojis, normalize whitespace, lowercase.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    # Remove HTML\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    # Remove emojis\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Lowercase\n",
        "    return text.lower().strip()\n",
        "\n",
        "def extract_keywords(sentence):\n",
        "    \"\"\"Extract important keywords from a full sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    keywords = []\n",
        "    for token in doc:\n",
        "        if token.is_stop:\n",
        "            continue\n",
        "        if token.pos_ in ['NOUN', 'PROPN']:  # nouns and proper nouns\n",
        "            keywords.append(token.text)\n",
        "    return \" \".join(keywords)\n",
        "\n",
        "def fetch_tweets(query, max_results=20):\n",
        "    \"\"\"Fetch recent tweets using X API (Tweepy).\"\"\"\n",
        "    client = tweepy.Client(X_API_BEARER_TOKEN)\n",
        "    response = client.search_recent_tweets(\n",
        "        query=f'{query} lang:en',  # only English tweets\n",
        "        max_results=max_results,\n",
        "        tweet_fields=['created_at', 'public_metrics', 'attachments'],\n",
        "        user_fields=['name', 'username', 'verified'],\n",
        "        media_fields=['url', 'preview_image_url', 'type'],\n",
        "        expansions=['author_id', 'attachments.media_keys']\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def preprocess_tweets(response):\n",
        "    \"\"\"Preprocess tweets and return a DataFrame.\"\"\"\n",
        "    if not response or not response.data:\n",
        "        return pd.DataFrame()  # empty dataframe if no tweets\n",
        "\n",
        "    tweets = response.data\n",
        "    users = {user['id']: user for user in response.includes.get('users', [])} if response.includes else {}\n",
        "    media = {m['media_key']: m for m in response.includes.get('media', [])} if response.includes else {}\n",
        "\n",
        "    processed = []\n",
        "    for tweet in tweets:\n",
        "        author = users.get(tweet.author_id)\n",
        "        media_urls = []\n",
        "\n",
        "        if hasattr(tweet, 'attachments') and 'media_keys' in tweet.attachments:\n",
        "            for key in tweet.attachments['media_keys']:\n",
        "                if key in media and media[key].type == 'photo':\n",
        "                    media_urls.append(media[key].url)\n",
        "\n",
        "        processed.append({\n",
        "            \"published_at\": tweet.created_at,\n",
        "            \"tweet_text\": clean_text(tweet.text),\n",
        "            \"author_name\": author.name if author else \"\",\n",
        "            \"author_username\": author.username if author else \"\",\n",
        "            \"author_verified\": author.verified if author else False,\n",
        "            \"tweet_url\": f\"https://x.com/{author.username}/status/{tweet.id}\" if author else \"\",\n",
        "            \"author_url\": f\"https://x.com/{author.username}\" if author else \"\",\n",
        "            \"image_urls\": media_urls\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(processed)\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "news_check = news_check.strip()\n",
        "\n",
        "if not X_API_BEARER_TOKEN or not news_check:\n",
        "    print(\"ERROR: Both the Bearer Token and the news sentence are required.\")\n",
        "else:\n",
        "    try:\n",
        "        # Step 1: Extract keywords\n",
        "        keywords_query = extract_keywords(news_check)\n",
        "        print(f\"Searching tweets using keywords: {keywords_query}\")\n",
        "\n",
        "        # Step 2: Fetch tweets using keywords\n",
        "        response = fetch_tweets(keywords_query)\n",
        "\n",
        "        # Step 3: Preprocess and display tweets\n",
        "        df = preprocess_tweets(response)\n",
        "        if df.empty:\n",
        "            print(\"\\nNo recent tweets found for the given news keywords.\")\n",
        "        else:\n",
        "            print(df)\n",
        "\n",
        "            # Optional: Save preprocessed tweets for ML/NLP\n",
        "            df.to_csv('preprocessed_tweets.csv', index=False)\n",
        "            print(\"\\nData saved to 'preprocessed_tweets.csv'.\")\n",
        "\n",
        "    except tweepy.errors.Unauthorized:\n",
        "        print(\"\\n--- AUTHENTICATION ERROR ---\\nCheck your Bearer Token.\")\n",
        "    except tweepy.errors.BadRequest:\n",
        "        print(\"\\n--- INVALID SEARCH QUERY ---\\nCheck your query format.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "0_Tsy4f98ag3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e339c9c-4118-45a7-aff4-b980557f6422"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching tweets using keywords: india pakistan war\n",
            "\n",
            "An unexpected error occurred: argument of type 'NoneType' is not iterable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Import libraries ---\n",
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "from bs4 import BeautifulSoup\n",
        "import tweepy\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Load SpaCy model for keyword extraction ---\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# --- Your X API Bearer Token ---\n",
        "X_API_BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAKCJ4QEAAAAAcEQy2tIw03BHpMFUg3fg9sbpGu8%3Db2Q2D7tbJUI2A0fJjOOMz69iKILmCmXeBYwVNNoxOaty3y2Oj2\"\n",
        "\n",
        "# --- Functions ---\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text: remove HTML, emojis, normalize whitespace, lowercase.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    # Remove HTML\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    # Remove emojis\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    # Lowercase\n",
        "    return text.lower().strip()\n",
        "\n",
        "def extract_keywords_tfidf(text, top_n=15):\n",
        "    \"\"\"Extract keywords using TF-IDF from the news text.\"\"\"\n",
        "    # Clean text\n",
        "    text_clean = clean_text(text)\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform([text_clean])\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    scores = tfidf_matrix.toarray()[0]\n",
        "    # Pick top N keywords\n",
        "    top_indices = scores.argsort()[-top_n:][::-1]\n",
        "    top_keywords = [feature_names[i] for i in top_indices]\n",
        "    return top_keywords\n",
        "\n",
        "def clean_keywords_for_query(keywords):\n",
        "    \"\"\"Clean keywords to avoid special character issues for X API search.\"\"\"\n",
        "    cleaned = [re.sub(r'[^A-Za-z0-9]', '', kw) for kw in keywords if kw.strip()]\n",
        "    return [kw for kw in cleaned if kw]  # remove empty strings\n",
        "\n",
        "def fetch_tweets(query, max_results=20):\n",
        "    \"\"\"Fetch recent tweets using X API (Tweepy).\"\"\"\n",
        "    client = tweepy.Client(X_API_BEARER_TOKEN)\n",
        "    response = client.search_recent_tweets(\n",
        "        query=f'{query} lang:en',  # only English tweets\n",
        "        max_results=max_results,\n",
        "        tweet_fields=['created_at', 'public_metrics', 'attachments'],\n",
        "        user_fields=['name', 'username', 'verified'],\n",
        "        media_fields=['url', 'preview_image_url', 'type'],\n",
        "        expansions=['author_id', 'attachments.media_keys']\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def preprocess_tweets(response, news_keywords):\n",
        "    \"\"\"Preprocess tweets and return a DataFrame with relevance score.\"\"\"\n",
        "    if not response or not response.data:\n",
        "        return pd.DataFrame()  # empty dataframe if no tweets\n",
        "\n",
        "    tweets = response.data\n",
        "    users = {user['id']: user for user in response.includes.get('users', [])} if response.includes else {}\n",
        "    media = {m['media_key']: m for m in response.includes.get('media', [])} if response.includes else {}\n",
        "\n",
        "    processed = []\n",
        "    for tweet in tweets:\n",
        "        author = users.get(tweet.author_id)\n",
        "        media_urls = []\n",
        "\n",
        "        if hasattr(tweet, 'attachments') and 'media_keys' in tweet.attachments:\n",
        "            for key in tweet.attachments['media_keys']:\n",
        "                if key in media and media[key].type == 'photo':\n",
        "                    media_urls.append(media[key].url)\n",
        "\n",
        "        tweet_text_clean = clean_text(tweet.text)\n",
        "\n",
        "        # Compute relevance using TF-IDF cosine similarity\n",
        "        combined_texts = [' '.join(news_keywords), tweet_text_clean]\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(combined_texts)\n",
        "        relevance = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "\n",
        "        processed.append({\n",
        "            \"published_at\": tweet.created_at,\n",
        "            \"tweet_text\": tweet_text_clean,\n",
        "            \"author_name\": author.name if author else \"\",\n",
        "            \"author_username\": author.username if author else \"\",\n",
        "            \"author_verified\": author.verified if author else False,\n",
        "            \"tweet_url\": f\"https://x.com/{author.username}/status/{tweet.id}\" if author else \"\",\n",
        "            \"author_url\": f\"https://x.com/{author.username}\" if author else \"\",\n",
        "            \"image_urls\": media_urls,\n",
        "            \"relevance\": relevance\n",
        "        })\n",
        "\n",
        "    # Sort by relevance\n",
        "    df = pd.DataFrame(processed)\n",
        "    df = df.sort_values(by='relevance', ascending=False).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "\n",
        "if not X_API_BEARER_TOKEN or not news_check:\n",
        "    print(\"ERROR: Both the Bearer Token and the news sentence are required.\")\n",
        "else:\n",
        "    try:\n",
        "        # Step 1: Extract keywords using TF-IDF\n",
        "        news_keywords = extract_keywords_tfidf(news_check, top_n=15)\n",
        "        # Clean keywords for X search\n",
        "        keywords_query = clean_keywords_for_query(news_keywords)\n",
        "        query_string = ' '.join(keywords_query)\n",
        "        print(f\"Searching tweets using cleaned keywords: {query_string}\")\n",
        "\n",
        "        # Step 2: Fetch tweets using keywords\n",
        "        response = fetch_tweets(query_string, max_results=50)\n",
        "\n",
        "        # Step 3: Preprocess tweets and compute relevance\n",
        "        df = preprocess_tweets(response, news_keywords)\n",
        "        if df.empty:\n",
        "            print(\"\\nNo recent tweets found for the given news keywords.\")\n",
        "        else:\n",
        "            print(df)\n",
        "\n",
        "            # Optional: Save preprocessed tweets for ML/NLP\n",
        "            df.to_csv('preprocessed_tweets.csv', index=False)\n",
        "            print(\"\\nData saved to 'preprocessed_tweets.csv'.\")\n",
        "\n",
        "    except tweepy.errors.Unauthorized:\n",
        "        print(\"\\n--- AUTHENTICATION ERROR ---\\nCheck your Bearer Token.\")\n",
        "    except tweepy.errors.BadRequest:\n",
        "        print(\"\\n--- INVALID SEARCH QUERY ---\\nCheck your query format.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "OCCfqZA3BZeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5c51b5-bd25-4b3a-f79c-56fe13a54c77"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching tweets using cleaned keywords: war pakistan india\n",
            "\n",
            "An unexpected error occurred: 429 Too Many Requests\n",
            "Too Many Requests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Reddit's datas in csv file*"
      ],
      "metadata": {
        "id": "dsrJmj_j-AlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw\n",
        "!pip install rake_nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHQmM0lTsw3n",
        "outputId": "4e499d52-8254-4456-c1e9-808a55afad78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.12/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.12/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.12/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from praw) (1.9.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from prawcore<3,>=2.4->praw) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.10.5)\n",
            "Collecting rake_nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from rake_nltk) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.67.1)\n",
            "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: rake_nltk\n",
            "Successfully installed rake_nltk-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import emoji\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Reddit API Configuration ---\n",
        "REDDIT_CLIENT_ID = 'utnSmiRRrv9ZDIlJ9LveMg'\n",
        "REDDIT_CLIENT_SECRET = 'jzP9XRolmRsu3CNiDZmKF0IDDGcXpA'\n",
        "REDDIT_USER_AGENT = 'python:moonsearcher:v1.0 (by /u/Dependent_Car_5879)'\n",
        "\n",
        "# --- SpaCy NER ---\n",
        "try:\n",
        "    import spacy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    USE_SPACY = True\n",
        "except:\n",
        "    USE_SPACY = False\n",
        "    print(\"⚠ spaCy model not found. Falling back to regex-based extraction.\")\n",
        "\n",
        "# ----------------- Utilities -----------------\n",
        "\n",
        "def clean_text(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip().lower()\n",
        "\n",
        "def extract_keywords(text):\n",
        "    if not text:\n",
        "        return []\n",
        "    keywords = set()\n",
        "    # Numbers / Percentages\n",
        "    keywords.update(re.findall(r'\\b\\d+(\\.\\d+)?%\\b', text))\n",
        "    keywords.update(re.findall(r'\\b\\d{1,6}\\b', text))\n",
        "    # Dates\n",
        "    keywords.update(re.findall(r'\\b(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*\\.?\\s+\\d{1,2},?\\s*\\d{0,4}\\b', text, re.IGNORECASE))\n",
        "\n",
        "    if USE_SPACY:\n",
        "        doc = nlp(text)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in [\"PERSON\",\"ORG\",\"GPE\",\"DATE\",\"TIME\",\"PERCENT\",\"MONEY\",\"QUANTITY\"]:\n",
        "                keywords.add(ent.text)\n",
        "    else:\n",
        "        # Fallback names\n",
        "        name_matches = re.findall(r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+)\\b', text)\n",
        "        keywords.update(name_matches)\n",
        "\n",
        "    return list(set([kw.strip() for kw in keywords if len(kw) > 1]))\n",
        "\n",
        "# ----------------- Reddit Fetch -----------------\n",
        "\n",
        "def fetch_reddit_posts(query, max_posts=500):\n",
        "    reddit = praw.Reddit(\n",
        "        client_id=REDDIT_CLIENT_ID,\n",
        "        client_secret=REDDIT_CLIENT_SECRET,\n",
        "        user_agent=REDDIT_USER_AGENT\n",
        "    )\n",
        "\n",
        "    subreddit = reddit.subreddit(\"all\")\n",
        "    submissions = []\n",
        "\n",
        "    for submission in subreddit.search(query=query, sort='new', limit=None):\n",
        "        submissions.append(submission)\n",
        "        if len(submissions) >= max_posts:\n",
        "            break\n",
        "\n",
        "    print(f\"Fetched {len(submissions)} posts from Reddit.\")\n",
        "    return submissions\n",
        "\n",
        "# ----------------- Relevance -----------------\n",
        "\n",
        "def compute_relevance(news_keywords, post_text):\n",
        "    combined_texts = [' '.join(news_keywords), post_text]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(combined_texts)\n",
        "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "    return similarity[0][0]\n",
        "\n",
        "# ----------------- Preprocess -----------------\n",
        "\n",
        "def preprocess_reddit_posts(submissions, news_keywords):\n",
        "    processed = []\n",
        "    for submission in submissions:\n",
        "        author_name = submission.author.name if submission.author else \"[deleted]\"\n",
        "        post_url = f\"https://www.reddit.com{submission.permalink}\"\n",
        "        author_url = f\"https://www.reddit.com/user/{author_name}\" if author_name != \"[deleted]\" else \"N/A\"\n",
        "        published_time = datetime.datetime.fromtimestamp(submission.created_utc)\n",
        "        full_text = clean_text(submission.title + \" \" + submission.selftext)\n",
        "        post_keywords = extract_keywords(full_text)\n",
        "        relevance = compute_relevance(news_keywords, full_text)\n",
        "        relevant_keywords = [kw for kw in post_keywords if kw.lower() in [k.lower() for k in news_keywords]]\n",
        "        processed.append({\n",
        "            \"published_at\": published_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            \"title\": clean_text(submission.title),\n",
        "            \"selftext\": clean_text(submission.selftext),\n",
        "            \"subreddit\": submission.subreddit.display_name,\n",
        "            \"score\": submission.score,\n",
        "            \"upvote_ratio\": submission.upvote_ratio,\n",
        "            \"author_name\": author_name,\n",
        "            \"author_url\": author_url,\n",
        "            \"post_url\": post_url,\n",
        "            \"keywords\": relevant_keywords,\n",
        "            \"relevance\": relevance\n",
        "        })\n",
        "\n",
        "    # Sort by relevance descending\n",
        "    processed = sorted(processed, key=lambda x: x['relevance'], reverse=True)\n",
        "    return pd.DataFrame(processed)\n",
        "\n",
        "# ----------------- Main -----------------\n",
        "\n",
        "news_text = news_check\n",
        "news_keywords = extract_keywords(news_text)\n",
        "query = ' '.join(news_keywords)\n",
        "\n",
        "submissions = fetch_reddit_posts(query, max_posts=500)\n",
        "df = preprocess_reddit_posts(submissions, news_keywords=news_keywords)\n",
        "\n",
        "df.to_csv('relevant_reddit_posts.csv', index=False)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUvOPpep-IjZ",
        "outputId": "7178e089-d812-4d23-ca7e-c78045a8f3ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched 249 posts from Reddit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1595525740.py:29: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
            "\n",
            "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
            "\n",
            "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
            "\n",
            "    from bs4 import MarkupResemblesLocatorWarning\n",
            "    import warnings\n",
            "\n",
            "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
            "    \n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            published_at                                              title  \\\n",
            "0    2025-10-16 16:41:30  india stands firmly with afghanistan against p...   \n",
            "1    2025-10-14 03:27:54  afghanistan-pakistan conflict – and why india ...   \n",
            "2    2025-10-16 15:32:11  india says, \"it stands with afghanistan agains...   \n",
            "3    2025-10-16 21:20:02  india vs pakistan world cup game breaks women'...   \n",
            "4    2025-10-14 13:00:35  pakistan defence minister khawaja asif sparked...   \n",
            "..                   ...                                                ...   \n",
            "244  2025-10-14 09:37:47             fifa world cup 2026 group stage leaked   \n",
            "245  2025-10-14 08:40:43                                peaceful president…   \n",
            "246  2025-10-14 07:04:56  from r/coolguides, australian medical educatio...   \n",
            "247  2025-10-14 06:21:07                      wtc standings after ind vs wi   \n",
            "248  2025-10-14 03:21:23  guys i think our neighbours still think they w...   \n",
            "\n",
            "                                              selftext             subreddit  \\\n",
            "0                                                                   TimesNow   \n",
            "1                                                                      india   \n",
            "2                                                              sundaysarthak   \n",
            "3    india vs pakistan world cup game breaks women'...             u_WTXNews   \n",
            "4                                                       IndiaTodayGlobalLIVE   \n",
            "..                                                 ...                   ...   \n",
            "244                                                         soccercirclejerk   \n",
            "245                                                           EnoughMuskSpam   \n",
            "246                                                                 ausjdocs   \n",
            "247                                                             IndiaCricket   \n",
            "248                                                              indianmemer   \n",
            "\n",
            "     score  upvote_ratio           author_name  \\\n",
            "0       47          0.78      SuperbHealth5023   \n",
            "1        4          0.70  Maleficent_Fault_943   \n",
            "2        8          0.90             deva82511   \n",
            "3        1          1.00               WTXNews   \n",
            "4        1          1.00      IndiaTodayGlobal   \n",
            "..     ...           ...                   ...   \n",
            "244    510          0.89   IndicationBrief5950   \n",
            "245   1162          0.98        Soft_Cable5934   \n",
            "246     49          0.68          -sportsball-   \n",
            "247    136          0.99     404-PulseNotFound   \n",
            "248      5          0.78  Popular_Barnacle_512   \n",
            "\n",
            "                                           author_url  \\\n",
            "0        https://www.reddit.com/user/SuperbHealth5023   \n",
            "1    https://www.reddit.com/user/Maleficent_Fault_943   \n",
            "2               https://www.reddit.com/user/deva82511   \n",
            "3                 https://www.reddit.com/user/WTXNews   \n",
            "4        https://www.reddit.com/user/IndiaTodayGlobal   \n",
            "..                                                ...   \n",
            "244   https://www.reddit.com/user/IndicationBrief5950   \n",
            "245        https://www.reddit.com/user/Soft_Cable5934   \n",
            "246          https://www.reddit.com/user/-sportsball-   \n",
            "247     https://www.reddit.com/user/404-PulseNotFound   \n",
            "248  https://www.reddit.com/user/Popular_Barnacle_512   \n",
            "\n",
            "                                              post_url keywords  relevance  \n",
            "0    https://www.reddit.com/r/TimesNow/comments/1o8...       []   0.410363  \n",
            "1    https://www.reddit.com/r/india/comments/1o64u8...       []   0.410363  \n",
            "2    https://www.reddit.com/r/sundaysarthak/comment...       []   0.379978  \n",
            "3    https://www.reddit.com/r/u_WTXNews/comments/1o...       []   0.371785  \n",
            "4    https://www.reddit.com/r/IndiaTodayGlobalLIVE/...       []   0.355477  \n",
            "..                                                 ...      ...        ...  \n",
            "244  https://www.reddit.com/r/soccercirclejerk/comm...       []   0.000000  \n",
            "245  https://www.reddit.com/r/EnoughMuskSpam/commen...       []   0.000000  \n",
            "246  https://www.reddit.com/r/ausjdocs/comments/1o6...       []   0.000000  \n",
            "247  https://www.reddit.com/r/IndiaCricket/comments...       []   0.000000  \n",
            "248  https://www.reddit.com/r/indianmemer/comments/...       []   0.000000  \n",
            "\n",
            "[249 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Dataframe\n",
        "real_news = pd.read_csv('preprocessed_news.csv')\n",
        "twitter_posts = pd.read_csv('preprocessed_tweets.csv')\n",
        "reddit_posts = pd.read_csv('relevant_reddit_posts.csv')"
      ],
      "metadata": {
        "id": "y-QIspMZ-WVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "2ad1d732-e9a4-4896-c340-27bd43b339de"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'preprocessed_tweets.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-981159306.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Creating Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreal_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessed_news.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtwitter_posts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessed_tweets.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mreddit_posts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relevant_reddit_posts.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preprocessed_tweets.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_news"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "tJIYm28JAt3c",
        "outputId": "487f1d88-eb2b-4f04-a393-11362c019ae7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'real_news' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1593937595.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreal_news\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'real_news' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_posts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "ExqDYWsxAxPb",
        "outputId": "87158ccb-f062-4059-b15e-5a81e185697b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                published_at  \\\n",
              "0  2025-10-16 07:38:26+00:00   \n",
              "1  2025-10-16 07:38:21+00:00   \n",
              "2  2025-10-16 07:38:11+00:00   \n",
              "3  2025-10-16 07:38:01+00:00   \n",
              "4  2025-10-16 07:37:48+00:00   \n",
              "5  2025-10-16 07:37:44+00:00   \n",
              "6  2025-10-16 07:37:41+00:00   \n",
              "7  2025-10-16 07:37:35+00:00   \n",
              "8  2025-10-16 07:37:34+00:00   \n",
              "9  2025-10-16 07:37:23+00:00   \n",
              "\n",
              "                                          tweet_text        author_name  \\\n",
              "0  breaking: trump says modi told him that india ...              Ounka   \n",
              "1  pm modi's dedication to serving the nation is ...        Rekanjadhav   \n",
              "2  modi’s path to viksit bharat goes through its ...  Dhruvkishor Patil   \n",
              "3  the story of two, bold and clear, mallanna’s v...              aakas   \n",
              "4  mallanna stands with fearless tone, facing pow...              vikas   \n",
              "5  the modi government’s new wave of war talk aga...        MISHAL KHAN   \n",
              "6  in response to u.s. president donald trump's c...            Peek TV   \n",
              "7  @rapidresponse47 @potus modi to trump: https:/...        vadapav ugh   \n",
              "8  mallanna stands with fearless tone, facing pow...              varun   \n",
              "9  guys do you know that our pm narendra modi is ...        Rintu Pawar   \n",
              "\n",
              "   author_username  author_verified  \\\n",
              "0         OunkaOnX            False   \n",
              "1         rekana24            False   \n",
              "2     DhruvkishorP            False   \n",
              "3       aakas27366            False   \n",
              "4       vikas26366            False   \n",
              "5  MishalKhanNDU12            False   \n",
              "6        PeekTV_in            False   \n",
              "7      magnoninsig            False   \n",
              "8    varunjaat7171            False   \n",
              "9        rintu_off            False   \n",
              "\n",
              "                                           tweet_url  \\\n",
              "0  https://x.com/OunkaOnX/status/1978727218252513742   \n",
              "1  https://x.com/rekana24/status/1978727197130252694   \n",
              "2  https://x.com/DhruvkishorP/status/197872715528...   \n",
              "3  https://x.com/aakas27366/status/19787271147542...   \n",
              "4  https://x.com/vikas26366/status/19787270594603...   \n",
              "5  https://x.com/MishalKhanNDU12/status/197872704...   \n",
              "6  https://x.com/PeekTV_in/status/197872703068740...   \n",
              "7  https://x.com/magnoninsig/status/1978727006406...   \n",
              "8  https://x.com/varunjaat7171/status/19787270020...   \n",
              "9  https://x.com/rintu_off/status/197872695404072...   \n",
              "\n",
              "                      author_url  \\\n",
              "0         https://x.com/OunkaOnX   \n",
              "1         https://x.com/rekana24   \n",
              "2     https://x.com/DhruvkishorP   \n",
              "3       https://x.com/aakas27366   \n",
              "4       https://x.com/vikas26366   \n",
              "5  https://x.com/MishalKhanNDU12   \n",
              "6        https://x.com/PeekTV_in   \n",
              "7      https://x.com/magnoninsig   \n",
              "8    https://x.com/varunjaat7171   \n",
              "9        https://x.com/rintu_off   \n",
              "\n",
              "                                          image_urls  \n",
              "0  ['https://pbs.twimg.com/media/G3XZ6SZXkAA3UQa....  \n",
              "1  ['https://pbs.twimg.com/media/G3XZ4NSWcAAq0cQ....  \n",
              "2  ['https://pbs.twimg.com/media/G3XZ25PWkAEXfPi....  \n",
              "3  ['https://pbs.twimg.com/media/G3XMZhDXkAARSHl....  \n",
              "4  ['https://pbs.twimg.com/media/G3XMZhDXkAARSHl....  \n",
              "5  ['https://pbs.twimg.com/media/G3XZVDiWMAA6TtD....  \n",
              "6  ['https://pbs.twimg.com/media/G3XZvruXAAAjgDk....  \n",
              "7  ['https://pbs.twimg.com/media/G3XZuRfW4AA2Pax....  \n",
              "8  ['https://pbs.twimg.com/media/G3XMZhDXkAARSHl....  \n",
              "9  ['https://pbs.twimg.com/media/G3XZrbEXcAAd7RC....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adfe74ef-f2ec-4b14-811f-c4fd3a746a2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>published_at</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>author_name</th>\n",
              "      <th>author_username</th>\n",
              "      <th>author_verified</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>author_url</th>\n",
              "      <th>image_urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-10-16 07:38:26+00:00</td>\n",
              "      <td>breaking: trump says modi told him that india ...</td>\n",
              "      <td>Ounka</td>\n",
              "      <td>OunkaOnX</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/OunkaOnX/status/1978727218252513742</td>\n",
              "      <td>https://x.com/OunkaOnX</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XZ6SZXkAA3UQa....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-10-16 07:38:21+00:00</td>\n",
              "      <td>pm modi's dedication to serving the nation is ...</td>\n",
              "      <td>Rekanjadhav</td>\n",
              "      <td>rekana24</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/rekana24/status/1978727197130252694</td>\n",
              "      <td>https://x.com/rekana24</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XZ4NSWcAAq0cQ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-10-16 07:38:11+00:00</td>\n",
              "      <td>modi’s path to viksit bharat goes through its ...</td>\n",
              "      <td>Dhruvkishor Patil</td>\n",
              "      <td>DhruvkishorP</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/DhruvkishorP/status/197872715528...</td>\n",
              "      <td>https://x.com/DhruvkishorP</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XZ25PWkAEXfPi....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-10-16 07:38:01+00:00</td>\n",
              "      <td>the story of two, bold and clear, mallanna’s v...</td>\n",
              "      <td>aakas</td>\n",
              "      <td>aakas27366</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/aakas27366/status/19787271147542...</td>\n",
              "      <td>https://x.com/aakas27366</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XMZhDXkAARSHl....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-10-16 07:37:48+00:00</td>\n",
              "      <td>mallanna stands with fearless tone, facing pow...</td>\n",
              "      <td>vikas</td>\n",
              "      <td>vikas26366</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/vikas26366/status/19787270594603...</td>\n",
              "      <td>https://x.com/vikas26366</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XMZhDXkAARSHl....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-10-16 07:37:44+00:00</td>\n",
              "      <td>the modi government’s new wave of war talk aga...</td>\n",
              "      <td>MISHAL KHAN</td>\n",
              "      <td>MishalKhanNDU12</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/MishalKhanNDU12/status/197872704...</td>\n",
              "      <td>https://x.com/MishalKhanNDU12</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XZVDiWMAA6TtD....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-10-16 07:37:41+00:00</td>\n",
              "      <td>in response to u.s. president donald trump's c...</td>\n",
              "      <td>Peek TV</td>\n",
              "      <td>PeekTV_in</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/PeekTV_in/status/197872703068740...</td>\n",
              "      <td>https://x.com/PeekTV_in</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XZvruXAAAjgDk....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-10-16 07:37:35+00:00</td>\n",
              "      <td>@rapidresponse47 @potus modi to trump: https:/...</td>\n",
              "      <td>vadapav ugh</td>\n",
              "      <td>magnoninsig</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/magnoninsig/status/1978727006406...</td>\n",
              "      <td>https://x.com/magnoninsig</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XZuRfW4AA2Pax....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-10-16 07:37:34+00:00</td>\n",
              "      <td>mallanna stands with fearless tone, facing pow...</td>\n",
              "      <td>varun</td>\n",
              "      <td>varunjaat7171</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/varunjaat7171/status/19787270020...</td>\n",
              "      <td>https://x.com/varunjaat7171</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XMZhDXkAARSHl....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-10-16 07:37:23+00:00</td>\n",
              "      <td>guys do you know that our pm narendra modi is ...</td>\n",
              "      <td>Rintu Pawar</td>\n",
              "      <td>rintu_off</td>\n",
              "      <td>False</td>\n",
              "      <td>https://x.com/rintu_off/status/197872695404072...</td>\n",
              "      <td>https://x.com/rintu_off</td>\n",
              "      <td>['https://pbs.twimg.com/media/G3XZrbEXcAAd7RC....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adfe74ef-f2ec-4b14-811f-c4fd3a746a2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-adfe74ef-f2ec-4b14-811f-c4fd3a746a2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-adfe74ef-f2ec-4b14-811f-c4fd3a746a2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7076ca93-d15d-4e14-bb44-f0c07dbbdd1d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7076ca93-d15d-4e14-bb44-f0c07dbbdd1d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7076ca93-d15d-4e14-bb44-f0c07dbbdd1d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_060546b3-9b5d-4edc-bb0b-cf44679a3a90\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('twitter_posts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_060546b3-9b5d-4edc-bb0b-cf44679a3a90 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('twitter_posts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "twitter_posts",
              "summary": "{\n  \"name\": \"twitter_posts\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"published_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2025-10-16 07:37:34+00:00\",\n          \"2025-10-16 07:38:21+00:00\",\n          \"2025-10-16 07:37:44+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"mallanna stands with fearless tone, facing power, all alone. modi builds with grand design, both walk india\\u2019s line. mallanna sevalo modhi https://t.co/cwht4rmbzj\",\n          \"pm modi's dedication to serving the nation is truly inspiring! just like lord mallanna's selfless service to devotees, pm modi's efforts are making a difference. mallanna sevalo modhi https://t.co/e88upqx7ic\",\n          \"the modi government\\u2019s new wave of war talk against pakistan is not strength but distraction. when domestic crises grow, new delhi turns to aggression to hide failures at home and mislead its own people. . . #modigovernment #\\u0e40\\u0e02\\u0e21\\u0e08\\u0e34\\u0e23\\u0e32\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e23\\u0e2d\\u0e14series #lagranjavip https://t.co/qekprbcgnw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"varun\",\n          \"Rekanjadhav\",\n          \"MISHAL KHAN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"varunjaat7171\",\n          \"rekana24\",\n          \"MishalKhanNDU12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_verified\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://x.com/varunjaat7171/status/1978727002078335340\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://x.com/varunjaat7171\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_urls\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"['https://pbs.twimg.com/media/G3XZ4NSWcAAq0cQ.jpg']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_posts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DzIz1PuBA_49",
        "outputId": "e7c4e973-6a2b-408d-bf80-77c32d0b81c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          published_at                                              title  \\\n",
              "0  2025-10-16 07:24:56                                      do you agree?   \n",
              "1  2025-10-16 07:17:53  us president donald trump claimed that prime m...   \n",
              "2  2025-10-16 07:16:09  qualcuno ha già parlato di equilibrio vita-lav...   \n",
              "3  2025-10-16 07:02:26  new narendra modi upload: live: pm modi perfor...   \n",
              "4  2025-10-16 06:46:53  trump says modi assured him india will halt ru...   \n",
              "5  2025-10-16 06:27:43  [business] - trump says modi has agreed to sto...   \n",
              "6  2025-10-16 06:27:42  [top stories] - trump says modi has agreed to ...   \n",
              "7  2025-10-16 06:24:00                       wait..... just a blank paper   \n",
              "8  2025-10-16 06:22:14  pawan kalyan grand welcome to pm narendra modi...   \n",
              "9  2025-10-16 06:17:34                            perfect use of the song   \n",
              "\n",
              "                                            selftext            subreddit  \\\n",
              "0                                                NaN           IndiaMemes   \n",
              "1  speaking to reporters on october 15, trump sai...    BusinessTodayNews   \n",
              "2                                                NaN     LinkedInCringeIT   \n",
              "3  this post contains content not supported on ol...   indian_discussions   \n",
              "4                                                NaN  u_Virtual_Swan_6551   \n",
              "5                                                NaN        AutoNewspaper   \n",
              "6                                                NaN        AutoNewspaper   \n",
              "7                                                NaN           IndiaMemes   \n",
              "8                                                NaN          pawankalyan   \n",
              "9                                                NaN                delhi   \n",
              "\n",
              "   score  upvote_ratio         author_name  \\\n",
              "0      3          1.00        Calm_Dash250   \n",
              "1      1          1.00       BusinessToday   \n",
              "2      5          1.00      Mondonauta0206   \n",
              "3      1          1.00              yt-app   \n",
              "4      1          1.00   Virtual_Swan_6551   \n",
              "5      1          1.00  AutoNewspaperAdmin   \n",
              "6      1          1.00  AutoNewspaperAdmin   \n",
              "7      3          1.00    Grumbling_Foot72   \n",
              "8      4          1.00  Perfect_Sector1888   \n",
              "9      2          0.55        kholeChature   \n",
              "\n",
              "                                       author_url  \\\n",
              "0        https://www.reddit.com/user/Calm_Dash250   \n",
              "1       https://www.reddit.com/user/BusinessToday   \n",
              "2      https://www.reddit.com/user/Mondonauta0206   \n",
              "3              https://www.reddit.com/user/yt-app   \n",
              "4   https://www.reddit.com/user/Virtual_Swan_6551   \n",
              "5  https://www.reddit.com/user/AutoNewspaperAdmin   \n",
              "6  https://www.reddit.com/user/AutoNewspaperAdmin   \n",
              "7    https://www.reddit.com/user/Grumbling_Foot72   \n",
              "8  https://www.reddit.com/user/Perfect_Sector1888   \n",
              "9        https://www.reddit.com/user/kholeChature   \n",
              "\n",
              "                                            post_url  \\\n",
              "0  https://www.reddit.com/r/IndiaMemes/comments/1...   \n",
              "1  https://www.reddit.com/r/BusinessTodayNews/com...   \n",
              "2  https://www.reddit.com/r/LinkedInCringeIT/comm...   \n",
              "3  https://www.reddit.com/r/indian_discussions/co...   \n",
              "4  https://www.reddit.com/r/u_Virtual_Swan_6551/c...   \n",
              "5  https://www.reddit.com/r/AutoNewspaper/comment...   \n",
              "6  https://www.reddit.com/r/AutoNewspaper/comment...   \n",
              "7  https://www.reddit.com/r/IndiaMemes/comments/1...   \n",
              "8  https://www.reddit.com/r/pawankalyan/comments/...   \n",
              "9  https://www.reddit.com/r/delhi/comments/1o7yp8...   \n",
              "\n",
              "                                           image_url  \n",
              "0               https://i.redd.it/1gnabsw1efvf1.jpeg  \n",
              "1                                                NaN  \n",
              "2               https://i.redd.it/gyfmp98gcfvf1.jpeg  \n",
              "3  https://external-preview.redd.it/nw6g1ihrhcMDV...  \n",
              "4                                                NaN  \n",
              "5  https://external-preview.redd.it/6hASWTjC-71TX...  \n",
              "6  https://external-preview.redd.it/6hASWTjC-71TX...  \n",
              "7               https://i.redd.it/9a0kd5993fvf1.jpeg  \n",
              "8               https://i.redd.it/zsiru3713fvf1.jpeg  \n",
              "9                https://i.redd.it/mylyqv072fvf1.png  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25cbe073-557a-4df9-a4fa-06e696693cc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>published_at</th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>author_name</th>\n",
              "      <th>author_url</th>\n",
              "      <th>post_url</th>\n",
              "      <th>image_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-10-16 07:24:56</td>\n",
              "      <td>do you agree?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IndiaMemes</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Calm_Dash250</td>\n",
              "      <td>https://www.reddit.com/user/Calm_Dash250</td>\n",
              "      <td>https://www.reddit.com/r/IndiaMemes/comments/1...</td>\n",
              "      <td>https://i.redd.it/1gnabsw1efvf1.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-10-16 07:17:53</td>\n",
              "      <td>us president donald trump claimed that prime m...</td>\n",
              "      <td>speaking to reporters on october 15, trump sai...</td>\n",
              "      <td>BusinessTodayNews</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>BusinessToday</td>\n",
              "      <td>https://www.reddit.com/user/BusinessToday</td>\n",
              "      <td>https://www.reddit.com/r/BusinessTodayNews/com...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-10-16 07:16:09</td>\n",
              "      <td>qualcuno ha già parlato di equilibrio vita-lav...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LinkedInCringeIT</td>\n",
              "      <td>5</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Mondonauta0206</td>\n",
              "      <td>https://www.reddit.com/user/Mondonauta0206</td>\n",
              "      <td>https://www.reddit.com/r/LinkedInCringeIT/comm...</td>\n",
              "      <td>https://i.redd.it/gyfmp98gcfvf1.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-10-16 07:02:26</td>\n",
              "      <td>new narendra modi upload: live: pm modi perfor...</td>\n",
              "      <td>this post contains content not supported on ol...</td>\n",
              "      <td>indian_discussions</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>yt-app</td>\n",
              "      <td>https://www.reddit.com/user/yt-app</td>\n",
              "      <td>https://www.reddit.com/r/indian_discussions/co...</td>\n",
              "      <td>https://external-preview.redd.it/nw6g1ihrhcMDV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-10-16 06:46:53</td>\n",
              "      <td>trump says modi assured him india will halt ru...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>u_Virtual_Swan_6551</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Virtual_Swan_6551</td>\n",
              "      <td>https://www.reddit.com/user/Virtual_Swan_6551</td>\n",
              "      <td>https://www.reddit.com/r/u_Virtual_Swan_6551/c...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-10-16 06:27:43</td>\n",
              "      <td>[business] - trump says modi has agreed to sto...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AutoNewspaper</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>AutoNewspaperAdmin</td>\n",
              "      <td>https://www.reddit.com/user/AutoNewspaperAdmin</td>\n",
              "      <td>https://www.reddit.com/r/AutoNewspaper/comment...</td>\n",
              "      <td>https://external-preview.redd.it/6hASWTjC-71TX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-10-16 06:27:42</td>\n",
              "      <td>[top stories] - trump says modi has agreed to ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>AutoNewspaper</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>AutoNewspaperAdmin</td>\n",
              "      <td>https://www.reddit.com/user/AutoNewspaperAdmin</td>\n",
              "      <td>https://www.reddit.com/r/AutoNewspaper/comment...</td>\n",
              "      <td>https://external-preview.redd.it/6hASWTjC-71TX...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-10-16 06:24:00</td>\n",
              "      <td>wait..... just a blank paper</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IndiaMemes</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Grumbling_Foot72</td>\n",
              "      <td>https://www.reddit.com/user/Grumbling_Foot72</td>\n",
              "      <td>https://www.reddit.com/r/IndiaMemes/comments/1...</td>\n",
              "      <td>https://i.redd.it/9a0kd5993fvf1.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-10-16 06:22:14</td>\n",
              "      <td>pawan kalyan grand welcome to pm narendra modi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pawankalyan</td>\n",
              "      <td>4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Perfect_Sector1888</td>\n",
              "      <td>https://www.reddit.com/user/Perfect_Sector1888</td>\n",
              "      <td>https://www.reddit.com/r/pawankalyan/comments/...</td>\n",
              "      <td>https://i.redd.it/zsiru3713fvf1.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-10-16 06:17:34</td>\n",
              "      <td>perfect use of the song</td>\n",
              "      <td>NaN</td>\n",
              "      <td>delhi</td>\n",
              "      <td>2</td>\n",
              "      <td>0.55</td>\n",
              "      <td>kholeChature</td>\n",
              "      <td>https://www.reddit.com/user/kholeChature</td>\n",
              "      <td>https://www.reddit.com/r/delhi/comments/1o7yp8...</td>\n",
              "      <td>https://i.redd.it/mylyqv072fvf1.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25cbe073-557a-4df9-a4fa-06e696693cc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25cbe073-557a-4df9-a4fa-06e696693cc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25cbe073-557a-4df9-a4fa-06e696693cc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b4070c31-bd4a-4adf-b9b0-e108f622f785\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4070c31-bd4a-4adf-b9b0-e108f622f785')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b4070c31-bd4a-4adf-b9b0-e108f622f785 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a29f15f8-6590-4201-9a0f-38ce90145f48\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('reddit_posts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a29f15f8-6590-4201-9a0f-38ce90145f48 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('reddit_posts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reddit_posts",
              "summary": "{\n  \"name\": \"reddit_posts\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"published_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2025-10-16 06:22:14\",\n          \"2025-10-16 07:17:53\",\n          \"2025-10-16 06:27:43\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"pawan kalyan grand welcome to pm narendra modi in kurnool\",\n          \"us president donald trump claimed that prime minister narendra modi has pledged to halt oil imports from russia, a move trump said could undercut moscow's war in ukraine.\",\n          \"[business] - trump says modi has agreed to stop buying russian oil | bbc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"selftext\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"this post contains content not supported on old reddit. [click here to view the full post](https://sh.reddit.com/r/indian_discussions/comments/1o7zed0)\",\n          \"speaking to reporters on october 15, trump said modi gave him personal assurances that india would stop buying russian oil, calling it \\u201ca big stop.\\u201d he added, \\u201cwe were not happy with him buying oil from russia because that lets russia continue with this ridiculous war... he assured me today that they will not be buying oil from russia.\\u201d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"BusinessTodayNews\",\n          \"AutoNewspaper\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvote_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14230249470757705,\n        \"min\": 0.55,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.55,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Perfect_Sector1888\",\n          \"BusinessToday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"https://www.reddit.com/user/Perfect_Sector1888\",\n          \"https://www.reddit.com/user/BusinessToday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"post_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"https://www.reddit.com/r/pawankalyan/comments/1o7yry6/pawan_kalyan_grand_welcome_to_pm_narendra_modi_in/\",\n          \"https://www.reddit.com/r/BusinessTodayNews/comments/1o7zmfw/us_president_donald_trump_claimed_that_prime/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"https://i.redd.it/1gnabsw1efvf1.jpeg\",\n          \"https://i.redd.it/gyfmp98gcfvf1.jpeg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hOIxCFb_BC6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}